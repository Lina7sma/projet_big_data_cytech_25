import os
import pandas as pd
import joblib
from sqlalchemy import create_engine
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import root_mean_squared_error
import numpy as np

def load_data():
    """
    Charge les donn√©es depuis la base de donn√©es PostgreSQL (Couche Gold).

    Returns
    -------
    pd.DataFrame
        Le dataset contenant les trajets de taxi pour l'entra√Ænement.
    """

    IS_DOCKER = os.path.exists('/.dockerenv')
    DB_HOST = "postgres" if IS_DOCKER else "localhost"

    # Utilisation de la variable DB_HOST dans l'URL
    engine = create_engine(f"postgresql://postgres:postgres@{DB_HOST}:5432/postgres")

    # On prend les colonnes cl√©s pour la pr√©diction
    query = """
            SELECT trip_distance, pickup_location_id, dropoff_location_id, EXTRACT(HOUR FROM pickup_datetime) as pickup_hour,
                   EXTRACT(DOW FROM pickup_datetime) as day_of_week, total_amount
            FROM fact_trips
            WHERE total_amount > 0 AND total_amount < 500
            LIMIT 1000000 \
            """
    return pd.read_sql(query, engine)

def train_and_evaluate(df):
    """
    Entra√Æne un mod√®le Random Forest et calcule sa performance.

    Parameters
    ----------
    df : pd.DataFrame
        Le dataframe contenant les features et la cible (total_amount).

    Returns
    -------
    model : RandomForestRegressor
        Le mod√®le entra√Æn√©.
    rmse : float
        L'erreur moyenne du mod√®le (doit √™tre < 10$).
    """
    # Pr√©paration des donn√©es
    X = df[['trip_distance', 'pickup_location_id', 'dropoff_location_id', 'pickup_hour', 'day_of_week']]
    y = df['total_amount']

    # D√©coupage 80% entra√Ænement / 20% test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Cr√©ation et entra√Ænement du mod√®le (100 arbres pour plus de pr√©cision)
    print(">>> Entra√Ænement du mod√®le en cours... (Cela peut prendre quelques minutes)")
    model = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42)
    model.fit(X_train, y_train)

    # Calcul de l'erreur
    predictions = model.predict(X_test)
    rmse = root_mean_squared_error(y_test, predictions)

    return model, rmse

def run_unit_tests(model):
    """
    Ex√©cute des tests unitaires pour valider la coh√©rence des pr√©dictions.

    Parameters
    ----------
    model : RandomForestRegressor
        Le mod√®le √† tester.
    """
    print(">>> Lancement des tests unitaires sur le mod√®le...")

    # Test 1: Une distance courte doit avoir un prix raisonnable
    test_data = pd.DataFrame([[1.0, 132, 132, 14, 5]],
                             columns=['trip_distance', 'pickup_location_id', 'dropoff_location_id', 'pickup_hour', 'day_of_week'])

    prediction = model.predict(test_data)[0]
    assert prediction > 0, "Test √©chou√© : prix n√©gatif !"
    assert prediction < 100, f"Test √©chou√© : prix trop √©lev√© pour 1 mile ({prediction}$)"

    print("‚úÖ Tous les tests unitaires sont pass√©s avec succ√®s !")

if __name__ == "__main__":
    # 1. Chargement
    print("üöÄ D√©marrage du Pipeline de Machine Learning")
    data = load_data()

    # 2. Entra√Ænement
    model, rmse_score = train_and_evaluate(data)
    print(f"üìä Performance du mod√®le (RMSE) : {rmse_score:.2f}$")
    print(f"üí° Objectif prof (< 10$) : {'REUSSI ‚úÖ' if rmse_score < 10 else 'A REVOIR ‚ùå'}")

    # 3. Tests unitaires (Exigence Prof)
    run_unit_tests(model)
    model.rmse_score = round(rmse_score, 2)
    # 4. Sauvegarde (Pour le Dashboard)
    joblib.dump(model, "taxi_model.joblib")
    print(f"üíæ Mod√®le sauvegard√© sous 'taxi_model.joblib' avec la valeur rmse {model.rmse_score}")